{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "215164bd-716a-438a-b83c-f5b5f8548ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Richard Restetzki\n",
    "# Exercise 1: Principles of Machine Learning\n",
    "\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import numpy.linalg as la\n",
    "import scipy.ndimage as img\n",
    "import itertools as iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a261acd7-6843-4b31-9b88-7c27f2874e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1.1 (Beware of numerical instabilities)\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9217f33d-7947-4a7a-a3c9-e8e0db54ce12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999992 0.99999992]\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1.1\n",
    "\n",
    "matX = np.array([[ 1.00000, 0.00000, 0.00000],\n",
    "[-1.00000, 0.00001, 0.00000]])\n",
    "vecY = np.array( [ 0.00000, 0.00001, 0.00000] )\n",
    "vecW = la.inv(matX @ matX.T) @ matX @ vecY\n",
    "print (vecW)\n",
    "\n",
    "# The solution is off by a slight bit because the matrix inverse is cannot be computed exactly with the given precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b887b0-6fb8-411e-9ebb-2ddb39fc2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1.2\n",
    "\n",
    "Xt_Q,Xt_R = la.qr(matX.T)\n",
    "vecW = la.inv(Xt_R) @ Xt_Q.T @ vecY\n",
    "print(vecW)\n",
    "\n",
    "# The solution is accurate because we only need to invert an upper triange matrix which can be done exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94915bce-924b-4a28-ad75-b4f2cdac7000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1.3\n",
    "\n",
    "vecW = la.lstsq(matX.T, vecY, rcond=-1)[0]\n",
    "print(vecW)\n",
    "\n",
    "# The method definitely does not use the eqution (3) directly as the parameter \"rcond=-1\" enforces the la.lstsq() function to use machine precision.\n",
    "# As we also used machine precision for Task 1.1.1 where (3) is solved directly, this should output in the same inaccurate result which it did not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7d8d9-6813-48b3-ba70-c1d80a41b703",
   "metadata": {},
   "source": [
    "Task 1.1.4\n",
    "\n",
    "Of course, rounding errors will emerge when using machine precision floats as representation for real numbers. Therefore, one should always think about the condition of the input arguments (in this case the input-matrix matX is not very well-conditioned) and the error propagation within our calculations. Inverting just any matrix should always be avoided where possible. As seen above, the replacement of a matrix inversion by inverting an upper triangle matrix is sufficient in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71d79d1-c6cf-4e6f-bff0-d3b68e6cf24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1.2 (cellular automata, the Boolean Fourier transform, and LSQ)\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38649c8f-d618-41ef-8970-68d5d5afd442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecY110:  [ 1 -1 -1 -1  1 -1 -1  1] ; vecYhat110:  [ 0.25 -0.25 -0.25 -0.75  0.75  0.25  0.25 -0.25]\n",
      "Residual for rule 110:  [ 0.75 -0.75 -0.75 -0.25  0.25 -1.25 -1.25  1.25]\n",
      "vecY126:  [ 1 -1 -1 -1 -1 -1 -1  1] ; vecYhat126:  [ 1.57009246e-16  0.00000000e+00  1.57009246e-16  0.00000000e+00\n",
      "  0.00000000e+00 -1.57009246e-16  0.00000000e+00 -1.57009246e-16]\n",
      "Residual for rule 126:  [ 1. -1. -1. -1. -1. -1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Task 1.2.1 [5 points]\n",
    "\n",
    "matX = np.array([[ 1,  1,  1,  1, -1, -1, -1, -1],\n",
    " [ 1,  1, -1, -1,  1,  1, -1, -1],\n",
    " [ 1, -1,  1, -1,  1, -1,  1, -1]])\n",
    "\n",
    "vecY110 = np.array([ 1,-1,-1,-1, 1,-1,-1, 1])\n",
    "vecW110 = la.lstsq(matX.T, vecY110, rcond=None)[0]\n",
    "vecYhat110 = matX.T @ vecW110\n",
    "print(\"vecY110: \", vecY110, \"; vecYhat110: \", vecYhat110)\n",
    "print(\"Residual for rule 110: \", vecY110-vecYhat110)\n",
    "\n",
    "vecY126 = np.array([ 1,-1,-1,-1,-1,-1,-1, 1])\n",
    "vecW126 = la.lstsq(matX.T, vecY126, rcond=None)[0]\n",
    "vecYhat126 = matX.T @ vecW126\n",
    "print(\"vecY126: \", vecY126, \"; vecYhat126: \", vecYhat126)\n",
    "print(\"Residual for rule 126: \", vecY126-vecYhat126)\n",
    "\n",
    "# The least squares problem cannot be fitted appropriately by linear models. In a way, we are prescribing a random 8-dimensional target vector\n",
    "# to our 3-dimensional feature map and expecting the emerging problem to be of linear nature which it is unsurprisingly not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df164a16-618f-465d-b913-0f710df3ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1.2.2 [5 points]\n",
    "\n",
    "def powerset(iterable):\n",
    "    # powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\n",
    "    s = list(iterable)\n",
    "    return iter.chain.from_iterable(iter.combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "def phi(vecX):\n",
    "    # This function realizes the transformation phi by taking any vector x and returning the vector phi(x) with size 2^n\n",
    "    n = vecX.shape[0]\n",
    "    vecPhiX = np.zeros(pow(2,n))\n",
    "    iteration = 0\n",
    "    for S in powerset(range(n)):\n",
    "        # This loop goes over every set S in the powerset of the index set I {0,1,...,n-1} (note that here the first index is 0 for obv. reasons)\n",
    "        # The powerset of the index set is used instead of directly creating the powerset of {x_i} as the x_i's might get large leading to a high memory usage\n",
    "        entry = 1\n",
    "        for index in S:\n",
    "            # This loop realizes the multiplication needed for computing phi_S(x)\n",
    "            entry *= vecX[index]\n",
    "        vecPhiX[iteration] = entry\n",
    "        iteration += 1\n",
    "    return vecPhiX\n",
    "\n",
    "# print (phi(np.array([2,3,5])))\n",
    "# print (phi(np.array([2,3,5,7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9c3a238-bc4e-4deb-bb60-36583558abe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecY110:  [ 1 -1 -1 -1  1 -1 -1  1] ; vecYhat110:  [ 1. -1. -1. -1.  1. -1. -1.  1.]\n",
      "Residual for rule 110:  [ 0.00000000e+00 -1.11022302e-16  2.22044605e-16 -3.33066907e-16\n",
      " -4.44089210e-16  0.00000000e+00 -4.44089210e-16  2.22044605e-16]\n",
      "vecY126:  [ 1 -1 -1 -1 -1 -1 -1  1] ; vecYhat126:  [ 1. -1. -1. -1. -1. -1. -1.  1.]\n",
      "Residual for rule 126:  [-4.44089210e-16 -1.11022302e-16  0.00000000e+00  2.22044605e-16\n",
      " -2.22044605e-16 -1.11022302e-16 -4.44089210e-16  4.44089210e-16]\n"
     ]
    }
   ],
   "source": [
    "# Task 1.2.3 [10 points]\n",
    "\n",
    "def Phi(matX):\n",
    "    n, size = matX.shape\n",
    "    matPhiXt = np.zeros( (size, pow(2,n)) )\n",
    "    for column in range(size):\n",
    "        # We replace each of the vectors x_i.T (rows of matX.T) with the respective lifted vectors phi_i.T (rows of matPhiXt)\n",
    "        matPhiXt[column] = phi(matX.T[column])\n",
    "    return matPhiXt.T\n",
    "\n",
    "matPhiX = Phi(matX)\n",
    "\n",
    "vecW110 = la.lstsq(matPhiX.T, vecY110, rcond=None)[0]\n",
    "vecYhat110 = matPhiX.T @ vecW110\n",
    "print(\"vecY110: \", vecY110, \"; vecYhat110: \", vecYhat110)\n",
    "print(\"Residual for rule 110: \", vecY110-vecYhat110)\n",
    "\n",
    "vecW126 = la.lstsq(matPhiX.T, vecY126, rcond=None)[0]\n",
    "vecYhat126 = matPhiX.T @ vecW126\n",
    "print(\"vecY126: \", vecY126, \"; vecYhat126: \", vecYhat126)\n",
    "print(\"Residual for rule 126: \", vecY126-vecYhat126)\n",
    "\n",
    "# The errors are negligible and we get a way better fit with a residual close to 0 at machine precision level\n",
    "# We had to pay for the good fit by increasing the dimension of the feature space to 2^n (=8 in this case)\n",
    "# This always allows a perfect fit for a 2^n dimensional target vector (assuming all functions in the feature space are independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484fe313-7816-4391-8d0c-c70fc130c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1.3 (Estimating the fractal dimension of objects in pictures)\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f205f02-bc59-42d8-9fb0-4141280b2f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard.Restetzki\\AppData\\Local\\Temp\\ipykernel_29488\\3219461498.py:6: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  imgD = np.abs(img.filters.gaussian_filter(imgF, sigma=0.50) - \\\n",
      "C:\\Users\\Richard.Restetzki\\AppData\\Local\\Temp\\ipykernel_29488\\3219461498.py:7: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  img.filters.gaussian_filter(imgF, sigma=1.00))\n",
      "C:\\Users\\Richard.Restetzki\\AppData\\Local\\Temp\\ipykernel_29488\\3219461498.py:9: DeprecationWarning: Please use `binary_closing` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n",
      "  return img.morphology.binary_closing(np.where(imgD < 0.1*imgD.max(), 0, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractal dimension of the Tree:  1.8463900565472446\n",
      "Fractal dimension of the Lightning:  1.4934991270542086\n"
     ]
    }
   ],
   "source": [
    "# Task 1.3.1 [20 points]\n",
    "\n",
    "def binarize(imgF):\n",
    "    # This does give DeprecationWarnings for the gaussian_filter and the binary_closing.\n",
    "    # The functions were not changed because this code was explicitly given within the exercise\n",
    "    imgD = np.abs(img.filters.gaussian_filter(imgF, sigma=0.50) - \\\n",
    "                    img.filters.gaussian_filter(imgF, sigma=1.00))\n",
    "    \n",
    "    return img.morphology.binary_closing(np.where(imgD < 0.1*imgD.max(), 0, 1))\n",
    "\n",
    "def linregression(vecX, vecY):\n",
    "    if vecX.shape==vecY.shape:\n",
    "        # Phi is the feature matrix for the linear regression with the data vector x\n",
    "        Phi = np.concatenate( ([np.ones(vecX.shape[0])], [vecX]), axis=0)\n",
    "        return la.lstsq(Phi.T, vecY, rcond=-1)[0]\n",
    "    else:\n",
    "        print(\"Input error: lin regression\")\n",
    "        return -1\n",
    "\n",
    "def fractaldim(imgF):\n",
    "    imgBin = binarize(imgF)\n",
    "    L = round(np.log2(imgBin.shape[0]))\n",
    "    # We store the l's in the scalings vector because the scaling of each iteration can be computed separately and then we don't need to compute the log\n",
    "    scalings = np.array(range(2,L))\n",
    "    counts = np.array(range(2,L))\n",
    "    for exponent in scalings:\n",
    "        # pow(2,L-exponent) is exactly the number of frames each with width pow(2,exponent) that can be fitted into the total width (same for height)\n",
    "        count = 0\n",
    "        for i in range(pow(2,L-exponent)):\n",
    "            for j in range(pow(2,L-exponent)):\n",
    "                # The condition of the if statement is only true if at least one pixel of the block in the i-th row and the j-th column is \"True\"\n",
    "                if np.any(imgBin[ (i*pow(2,exponent)):((i+1)*pow(2,exponent)), (j*pow(2,exponent)):((j+1)*pow(2,exponent))]):\n",
    "                    count += 1\n",
    "        counts[exponent-2] = count\n",
    "    scalings *= -1\n",
    "    scalings += L\n",
    "    # Return only the second of the optimal model parameters which corresponds to the slope of the linear function and thus the estimate D of the dimension\n",
    "    return linregression(scalings, np.log2(counts))[1]\n",
    "\n",
    "imgTree = iio.imread('tree.png', mode='L').astype(float)\n",
    "imgLightning = iio.imread('lightning.png', mode='L').astype(float)\n",
    "print(\"Fractal dimension of the Tree: \", fractaldim(imgTree))\n",
    "print(\"Fractal dimension of the Lightning: \", fractaldim(imgLightning))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
